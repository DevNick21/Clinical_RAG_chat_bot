\chapter{Background \& Literature Overview}
\section{Literature Review}

Retrieval-Augmented Generation (RAG) systems are emerging as a pivotal advancement in the field of Artificial Intelligence (AI), particularly within the clinical domain. These systems integrate Large Language Models (LLMs) with external knowledge sources to produce more accurate, contextually relevant, and reliable responses, addressing critical limitations inherent in standalone LLMs. The high-stakes nature of healthcare necessitates precise, up-to-date, and verifiable information, making RAG a particularly valuable tool for improving diagnostic accuracy, clinical decision support, and patient care.

This literature review comprehensively explores the application of RAG within clinical settings, building upon existing foundational work and considering various RAG methodologies, datasets, and ethical implications.

\subsection{Evolution of Language Models Leading to RAG}

The journey towards sophisticated language understanding systems has seen significant transformations. Initially, \textbf{Statistical Language Models (SLMs)} such as n-gram models, which emerged in the 1990s, used probabilistic statistics to model word sequences. These were succeeded by \textbf{Neural Language Models (NLMs)}, which employed neural networks to capture complex linguistic patterns.

Further progress led to \textbf{Recurrent Neural Networks (RNNs)} and, in particular, \textbf{Long Short-Term Memory (LSTM)} and \textbf{Gated Recurrent Neural Networks}, which were established as state-of-the-art for sequence modelling and transduction tasks. However, these architectures faced challenges in handling long-range contextual dependencies.

A significant breakthrough arrived with the introduction of the \textbf{Transformer architecture} in 2017, as detailed in ``Attention Is All You Need'' (\citep{vaswani2017attention}). This architecture fundamentally changed language modelling by replacing recurrence with \textit{self-attention mechanisms}, enabling highly parallel training and more efficient modelling of long-range dependencies.

The Transformer then became the backbone for \textbf{Pre-trained Language Models (PLMs)} such as BERT (\citep{devlin2019bert}) and OpenAI GPT (\citep{radford2019language}). PLMs use large-scale pre-training followed by task-specific fine-tuning.

\textbf{Large Language Models (LLMs)} extend PLMs by incorporating massive datasets, computation, and refined architectures. Models such as GPT-3 (\citep{brown2020language}), GPT-4, PaLM (\citep{chowdhery2022palm}) and LLaMA (\citep{touvron2023llama}) demonstrate zero-shot and few-shot reasoning. Their growth has been propelled by data diversity, specialised GPUs/TPUs, and algorithmic advances. Despite their fluency, LLMs suffer limitations: hallucinations, outdated knowledge, expensive retraining, and lack of transparency (\citep{ji2023survey}). These shortcomings are especially concerning in medicine, motivating the emergence of RAG.

\subsection{Emergence and Mechanics of Retrieval-Augmented Generation (RAG)}

RAG addresses LLM limitations by combining strong generative capabilities with \textbf{external memory retrieval}. Early work, such as REALM integrated retrieval into pre-training (\citep{guu2020realm}). Lewis et al. (\citeyear{lewis2020rag}) introduced RAG, pairing a neural retriever with a seq2seq generator: top-k passages are retrieved and used to ground output. Variants such as Fusion-in-Decoder (\citep{izacard2021leveraging}) and RETRO (\citep{borgeaud2022retro}) expanded retrieval to larger corpora. Frameworks like LangChain (\citep{langchain2023}) and LlamaIndex (\citep{llamaindex2023}) operationalised RAG pipelines.

The typical RAG pipeline has three steps:
\begin{itemize}
  \item \textbf{Indexing:} Documents segmented into chunks, embedded with encoders, and stored in vector databases (e.g., FAISS).
  \item \textbf{Retrieval:} Queries embedded, top-k chunks retrieved via similarity search.
  \item \textbf{Generation:} Query and retrieved chunks passed to the LLM for grounded response.
\end{itemize}

This allows factuality without retraining, making RAG especially attractive in healthcare.

\subsection{RAG Architectures and Methodologies in Healthcare}

\subsubsection{Naive RAG}
Naive RAG directly applies indexing, retrieval, and generation. Studies show RAG-enhanced GPT-4 can reach 99\% accuracy on hepatology guidelines compared to 43\% for GPT-4-Turbo alone (\citep{li2024liversa}). Systems such as ChatENT in otolaryngology (\citep{zhang2024chatent}) and Almanac in clinical QA (\citep{singhal2023almanac}) demonstrate fewer hallucinations. In EHR phenotyping, RAG-LLMs outperform rule-based methods (\citep{wu2024ragphenotype}).

\subsubsection{Advanced RAG}
Advanced RAG adds pre- and post-retrieval refinements: metadata filters, hybrid retrievers, and re-ranking. Knowledge graphs are integrated for richer reasoning. MedRAG, for example, combines a diagnostic KG with RAG to improve disease-specific QA and proactive questioning (\citep{zhao2025medrag}). Systems like RECTIFIER use RAG for trial eligibility screening, outperforming human staff in accuracy (\citep{wang2024rectifier}).

\subsubsection{Modular RAG}
Modular RAG employs multi-component systems: hybrid retrievers, multiple LLM agents, and prompt-engineered retrieval. Prompt-RAG (\citep{kim2024promptrag}) uses natural-language prompts instead of embeddings, while multi-agent approaches improve GPT-4 accuracy to 95\% (\citep{sun2025agenticrag}).

\subsection{Datasets in Clinical RAG Systems}

RAG relies on curated datasets. Frequently used corpora include PubMed, UMLS, MedDialog (\citep{chen2020meddialog}), MedDG (\citep{li2020meddg}), and imaging-text datasets such as MIMIC-CXR (\citep{johnson2019mimiccxr}). Benchmarks include BioASQ, MedMCQA, PubMedQA (\citep{jin2019pubmedqa}), MedQA (\citep{jin2021medqa}), MultiMedQA (\citep{singhal2023multimedqa}), ClinicalQA (\citep{abacha2021nlmclinicalqa}), and MIRAGE (\citep{zhu2023mirage}). Synthetic datasets such as DDXPlus (\citep{liu2023ddxplus}) and CPDD (\citep{zhao2025medrag}) test diagnostic QA.

Most datasets are English-only, limiting multilingual evaluation. This bias restricts fairness and highlights the need for broader language coverage.

\subsection{Ethical Considerations}

Healthcare RAG systems face risks: hallucinations, privacy breaches, bias, and lack of transparency. Patient-sensitive datasets (e.g., MIMIC-IV, \citep{johnson2023mimiciv}) require de-identification to ensure HIPAA/GDPR compliance. Bias in internet-trained LLMs persists even with retrieval (\citep{mehrabi2021survey}). RAG helps transparency by citing sources, but retrieval collapse remains a risk. Integration into workflows must avoid cognitive overload for clinicians.

\subsection{Beyond RAG: Future Directions for Clinical LLMs}

Looking past classical RAG, several trajectories are especially promising for clinical deployment:

\paragraph{Domain-specific foundation models.}
Open and proprietary medical LLMs fine-tuned on biomedical corpora show consistent gains over general models on exam-style and clinician-judged tasks, suggesting a path to safer, more aligned clinical assistants. Examples include Med-PaLM~2, which achieved expert-level responses on multiple medical benchmarks and was preferred by clinicians on most axes (\citep{singhal2024medpalm2}); MEDITRON-70B, which adapts LLaMA-2 via large-scale medical pretraining (\citep{chen2023meditron}); and GatorTron, trained on $>$82B tokens of de-identified clinical text to advance core clinical NLP tasks (\citep{yang2022gatortron}).

\paragraph{Diagnostic dialogue and longitudinal reasoning.}
Beyond single-turn QA, systems optimised for history taking and iterative differential diagnosis (DDx) indicate that LLMs can support the diagnostic process itself. Google's AMIE reports clinically preferred diagnostic dialogues and improved DDx support in controlled studies (\citep{amie2025nature,amie2024blog}). Embedding such models into triage, clerking, and MDT workflows is a natural next step.

\paragraph{Multimodal clinical models (text + imaging + signals).}
Vision language models specialised for medicine (e.g. LLaVA-Med and Med-Flamingo) demonstrate open-ended reasoning over biomedical figures and radiology, with clinical-rated gains in medical VQA and progress in report generation (\citep{llavamed2023,moor2023medflamingo,nature2024flamingocxr}). Extending RAG to \emph{multimodal RAG}, retrieving not just passages but also linked images and structured findings can provide better ground answers in PACS and reporting systems.

\paragraph{Graph-augmented and structure-aware retrieval.}
New pipelines like GraphRAG construct and query knowledge graphs over private corpora, improving recall and reasoning on narrative clinical data (\citep{larson2024graphrag,graphrag2024arxiv}). In healthcare, combining ontology-backed graphs (e.g., UMLS) with free-text retrieval may mitigate retrieval blind spots and support multi-hop guideline reasoning.

\paragraph{Agentic workflows and tool use.}
Multi-agent pipelines that plan, retrieve, verify and cite, rather than single-pass prompting, show accuracy gains in open-domain tasks and are well-suited to safety-critical settings (e.g., agent plans for guideline lookup, DDx cross-checks, and citation verification) (\citep{sun2025agenticrag}). Clinically, agents can orchestrate EHR queries (SQL, FHIR), calculator tools (risk scores) and literature checks before drafting notes.

\paragraph{Tight EHR integration and structured data grounding.}
Future systems should natively query structured sources (e.g. MIMIC-IVâ€“like schemas, FHIR servers) to ground generation in vitals, labs and medications, reducing hallucinations and enabling patient-specific recommendations (\citep{yang2022gatortron}). Coupling retrieval over notes with programmatic reads of structured fields is a practical near-term target.

\paragraph{Privacy-preserving and efficient adaptation.}
Given PHI constraints, parameter-efficient finetuning (e.g. LoRA/PEFT), federated or on-prem training, and auditable data pipelines are essential. Inference on the device and edge using distilled or quantised medical LLM could enable bedside use when the network or data sharing is restricted (\citep{chen2023meditron}).

\paragraph{Provenance, auditing and safety guardrails.}
Beyond point-in-time citations, future systems should expose evidence provenance graphs, uncertainty estimates, and contradiction checks against guidelines, with human-in-the-loop review. Emerging evaluations highlight that even strong medical LLMs have failure modes and access limitations that require robust oversight (\citep{nature2024evallimits}).

Overall, advances in domain-specialised models, multimodal grounding, graph-aware retrieval, agentic verification, and EHR-native tool use provide a concrete roadmap for clinical AI systems that go beyond classical RAG while retaining traceability and clinician control.

In conclusion, RAG augments LLMs to deliver more accurate, grounded, and clinically useful results. Although challenges remain, particularly around ethics, privacy, and data set bias, RAG represents a crucial pathway toward trustworthy AI in healthcare.
