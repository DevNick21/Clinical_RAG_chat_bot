{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2fbb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c7870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"mimic_sample_1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load admissions first\n",
    "admissions_df = pd.read_csv(Path(DATA_DIR) / \"admissions.csv_sample1000.csv\", parse_dates=[\"admittime\",\"dischtime\"],  low_memory=False)\n",
    "\n",
    "# Initialize link_tables\n",
    "link_tables = {}\n",
    "\n",
    "# Load tables that need special processing first\n",
    "# Diagnoses with ICD definitions\n",
    "icd_dx = pd.read_csv(Path(DATA_DIR) / \"d_icd_diagnoses.csv.csv\", low_memory=False)\n",
    "dx = pd.read_csv(Path(DATA_DIR) / \"diagnoses_icd.csv_sample1000.csv\", low_memory=False)\n",
    "link_tables[\"diagnoses_icd\"] = dx.merge(icd_dx, on=\"icd_code\", how=\"left\")\n",
    "\n",
    "# Procedures with ICD definitions\n",
    "icd_proc = pd.read_csv(Path(DATA_DIR) / \"d_icd_procedures.csv.csv\", low_memory=False)\n",
    "pr = pd.read_csv(Path(DATA_DIR) / \"procedures_icd.csv_sample1000.csv\", low_memory=False)\n",
    "link_tables[\"procedures_icd\"] = pr.merge(icd_proc, on=\"icd_code\", how=\"left\")\n",
    "\n",
    "# Lab events with definitions\n",
    "lab_defs = pd.read_csv(Path(DATA_DIR) / \"d_labitems.csv.csv\", low_memory=False)\n",
    "link_tables[\"labevents\"] = (\n",
    "    pd.read_csv(Path(DATA_DIR) / \"labevents.csv_sample1000.csv\", parse_dates=[\"charttime\",\"storetime\"], low_memory=False)\n",
    "    .merge(lab_defs, on=\"itemid\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Microbiology events with lab definitions\n",
    "link_tables[\"microbiologyevents\"] = (\n",
    "    pd.read_csv(Path(DATA_DIR) / \"microbiologyevents.csv_sample1000.csv\", parse_dates=[\"charttime\",\"storetime\", \"chartdate\",\"storedate\"], low_memory=False)\n",
    "    .merge(lab_defs, left_on=\"test_itemid\", right_on=\"itemid\", how=\"left\")\n",
    ")\n",
    "\n",
    "#! Note: The following tables are commented out as they are not used in the current context.\n",
    "# # HCPCS events with definitions\n",
    "# hcpcs_defs = pd.read_csv(DATA_DIR / \"d_hcpcs.csv.csv\", low_memory=False)\n",
    "# hcp = pd.read_csv(DATA_DIR / \"hcpcsevents.csv_sample1000.csv\", low_memory=False)\n",
    "# link_tables[\"hcpcsevents\"] = (\n",
    "#     hcp.merge(\n",
    "#         hcpcs_defs,\n",
    "#         left_on=\"hcpcs_cd\",\n",
    "#         right_on=\"code\",\n",
    "#         how=\"left\",\n",
    "#         suffixes=(\"\", \"_def\")\n",
    "#     )\n",
    "#     .rename(columns={\"short_description\": \"event_desc\",\n",
    "#                     \"short_description_def\": \"code_desc\"})\n",
    "#     .drop(columns=[\"code\"])\n",
    "# )\n",
    "\n",
    "# Load provider info for tables that need it\n",
    "prov = pd.read_csv(Path(DATA_DIR) / \"provider.csv.csv\", low_memory=False)\n",
    "\n",
    "# Merging Prescriptions, POE, and EMAR\n",
    "pres = pd.read_csv(Path(DATA_DIR) / \"prescriptions.csv_sample1000.csv\", low_memory=False)\n",
    "poe = pd.read_csv(Path(DATA_DIR) / \"poe.csv_sample1000.csv\", parse_dates=[\"ordertime\"], low_memory=False)\n",
    "emar = pd.read_csv(Path(DATA_DIR) / \"emar.csv_sample1000.csv\", parse_dates=[\"charttime\",\"storetime\"], low_memory=False)\n",
    "\n",
    "tmp = pd.merge(pres, poe, on=['poe_id','hadm_id'], how='left')\n",
    "link_tables[\"prescriptions\"] = pd.merge(tmp, emar, on=['poe_id','hadm_id'], how='left')\n",
    "\n",
    "\n",
    "# Load remaining tables with provider merging where applicable\n",
    "for tbl in [\"transfers\"]:\n",
    "    df = pd.read_csv(Path(DATA_DIR) / f\"{tbl}.csv_sample1000.csv\", low_memory=False)\n",
    "\n",
    "# Didn't see the need for provider and services\n",
    "\n",
    "    link_tables[tbl] = df\n",
    "\n",
    "# Group by hadm_id for constant‐time lookup\n",
    "grouped = {name: df.groupby(\"hadm_id\") for name, df in link_tables.items() if \"hadm_id\" in df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1066d1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['diagnoses_icd', 'procedures_icd', 'labevents', 'microbiologyevents', 'prescriptions', 'transfers'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_tables.keys()  # to see what tables we have loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c4aacc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "labevent_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "specimen_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "itemid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "order_provider_id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "charttime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "storetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "value",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "valuenum",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "valueuom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ref_range_lower",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ref_range_upper",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flag",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "priority",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "comments",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fluid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "cbce21f1-57f5-4f46-875e-952e623c23b7",
       "rows": [
        [
         "0",
         "112946",
         "10006508",
         "25282710.0",
         "394328",
         "50861",
         null,
         "2132-07-01 04:15:00",
         "2132-07-01 07:17:00",
         "16",
         "16.0",
         "IU/L",
         "0.0",
         "40.0",
         null,
         "ROUTINE",
         null,
         "Alanine Aminotransferase (ALT)",
         "Blood",
         "Chemistry"
        ],
        [
         "1",
         "112947",
         "10006508",
         "25282710.0",
         "394328",
         "50863",
         null,
         "2132-07-01 04:15:00",
         "2132-07-01 07:17:00",
         "104",
         "104.0",
         "IU/L",
         "35.0",
         "105.0",
         null,
         "ROUTINE",
         null,
         "Alkaline Phosphatase",
         "Blood",
         "Chemistry"
        ],
        [
         "2",
         "112948",
         "10006508",
         "25282710.0",
         "394328",
         "50868",
         null,
         "2132-07-01 04:15:00",
         "2132-07-01 08:01:00",
         "18",
         "18.0",
         "mEq/L",
         "8.0",
         "20.0",
         null,
         "ROUTINE",
         null,
         "Anion Gap",
         "Blood",
         "Chemistry"
        ],
        [
         "3",
         "112949",
         "10006508",
         "25282710.0",
         "394328",
         "50878",
         null,
         "2132-07-01 04:15:00",
         "2132-07-01 07:17:00",
         "22",
         "22.0",
         "IU/L",
         "0.0",
         "40.0",
         null,
         "ROUTINE",
         null,
         "Asparate Aminotransferase (AST)",
         "Blood",
         "Chemistry"
        ],
        [
         "4",
         "112950",
         "10006508",
         "25282710.0",
         "394328",
         "50882",
         null,
         "2132-07-01 04:15:00",
         "2132-07-01 07:17:00",
         "21",
         "21.0",
         "mEq/L",
         "22.0",
         "32.0",
         "abnormal",
         "ROUTINE",
         null,
         "Bicarbonate",
         "Blood",
         "Chemistry"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labevent_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>specimen_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>order_provider_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>priority</th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "      <th>fluid</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112946</td>\n",
       "      <td>10006508</td>\n",
       "      <td>25282710.0</td>\n",
       "      <td>394328</td>\n",
       "      <td>50861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2132-07-01 04:15:00</td>\n",
       "      <td>2132-07-01 07:17:00</td>\n",
       "      <td>16</td>\n",
       "      <td>16.0</td>\n",
       "      <td>IU/L</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alanine Aminotransferase (ALT)</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112947</td>\n",
       "      <td>10006508</td>\n",
       "      <td>25282710.0</td>\n",
       "      <td>394328</td>\n",
       "      <td>50863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2132-07-01 04:15:00</td>\n",
       "      <td>2132-07-01 07:17:00</td>\n",
       "      <td>104</td>\n",
       "      <td>104.0</td>\n",
       "      <td>IU/L</td>\n",
       "      <td>35.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alkaline Phosphatase</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112948</td>\n",
       "      <td>10006508</td>\n",
       "      <td>25282710.0</td>\n",
       "      <td>394328</td>\n",
       "      <td>50868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2132-07-01 04:15:00</td>\n",
       "      <td>2132-07-01 08:01:00</td>\n",
       "      <td>18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anion Gap</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112949</td>\n",
       "      <td>10006508</td>\n",
       "      <td>25282710.0</td>\n",
       "      <td>394328</td>\n",
       "      <td>50878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2132-07-01 04:15:00</td>\n",
       "      <td>2132-07-01 07:17:00</td>\n",
       "      <td>22</td>\n",
       "      <td>22.0</td>\n",
       "      <td>IU/L</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asparate Aminotransferase (AST)</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112950</td>\n",
       "      <td>10006508</td>\n",
       "      <td>25282710.0</td>\n",
       "      <td>394328</td>\n",
       "      <td>50882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2132-07-01 04:15:00</td>\n",
       "      <td>2132-07-01 07:17:00</td>\n",
       "      <td>21</td>\n",
       "      <td>21.0</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bicarbonate</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labevent_id  subject_id     hadm_id  specimen_id  itemid order_provider_id  \\\n",
       "0       112946    10006508  25282710.0       394328   50861               NaN   \n",
       "1       112947    10006508  25282710.0       394328   50863               NaN   \n",
       "2       112948    10006508  25282710.0       394328   50868               NaN   \n",
       "3       112949    10006508  25282710.0       394328   50878               NaN   \n",
       "4       112950    10006508  25282710.0       394328   50882               NaN   \n",
       "\n",
       "            charttime           storetime value  valuenum valueuom  \\\n",
       "0 2132-07-01 04:15:00 2132-07-01 07:17:00    16      16.0     IU/L   \n",
       "1 2132-07-01 04:15:00 2132-07-01 07:17:00   104     104.0     IU/L   \n",
       "2 2132-07-01 04:15:00 2132-07-01 08:01:00    18      18.0    mEq/L   \n",
       "3 2132-07-01 04:15:00 2132-07-01 07:17:00    22      22.0     IU/L   \n",
       "4 2132-07-01 04:15:00 2132-07-01 07:17:00    21      21.0    mEq/L   \n",
       "\n",
       "   ref_range_lower  ref_range_upper      flag priority comments  \\\n",
       "0              0.0             40.0       NaN  ROUTINE      NaN   \n",
       "1             35.0            105.0       NaN  ROUTINE      NaN   \n",
       "2              8.0             20.0       NaN  ROUTINE      NaN   \n",
       "3              0.0             40.0       NaN  ROUTINE      NaN   \n",
       "4             22.0             32.0  abnormal  ROUTINE      NaN   \n",
       "\n",
       "                             label  fluid   category  \n",
       "0   Alanine Aminotransferase (ALT)  Blood  Chemistry  \n",
       "1             Alkaline Phosphatase  Blood  Chemistry  \n",
       "2                        Anion Gap  Blood  Chemistry  \n",
       "3  Asparate Aminotransferase (AST)  Blood  Chemistry  \n",
       "4                      Bicarbonate  Blood  Chemistry  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_tables[\"labevents\"].head()  # to see the admissions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d2342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = Path(\"mimic_sample_1000/exports\")\n",
    "export_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export admissions_df\n",
    "with open(export_dir / \"admissions_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(admissions_df, f)\n",
    "\n",
    "# Export link_tables\n",
    "with open(export_dir / \"link_tables.pkl\", \"wb\") as f:\n",
    "    pickle.dump(link_tables, f)\n",
    "\n",
    "# Export grouped tables (for convenience)\n",
    "with open(export_dir / \"grouped_tables.pkl\", \"wb\") as f:\n",
    "    pickle.dump(grouped, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae6b63c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['microevent_id', 'subject_id', 'hadm_id', 'micro_specimen_id',\n",
       "       'order_provider_id', 'chartdate', 'charttime', 'spec_itemid',\n",
       "       'spec_type_desc', 'test_seq', 'storedate', 'storetime', 'test_itemid',\n",
       "       'test_name', 'org_itemid', 'org_name', 'isolate_num', 'quantity',\n",
       "       'ab_itemid', 'ab_name', 'dilution_text', 'dilution_comparison',\n",
       "       'dilution_value', 'interpretation', 'comments', 'itemid', 'label',\n",
       "       'fluid', 'category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_tables[\"microbiologyevents\"].columns  # to see the structure of the prescriptions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29855b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emitted 4527 small Documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def make_section_docs(adm_row, grouped):\n",
    "    hadm = adm_row.hadm_id\n",
    "    subj = adm_row.subject_id\n",
    "    base_meta = {\n",
    "        \"hadm_id\": hadm,\n",
    "        \"subject_id\": subj,\n",
    "        \"admittime\": adm_row.admittime.isoformat() if pd.notna(adm_row.admittime) else \"N/A\",\n",
    "        \"dischtime\": adm_row.dischtime.isoformat() if pd.notna(adm_row.dischtime) else \"N/A\",\n",
    "        \"admission_type\": adm_row.admission_type\n",
    "    }\n",
    "    docs = []\n",
    "    def safe(val, default=\"N/A\"):\n",
    "        if pd.isna(val) or (isinstance(val, str) and not val.strip()):\n",
    "            return default\n",
    "        return val\n",
    "\n",
    "    # — Header\n",
    "    header = (\n",
    "        f\"Admission {hadm} (Subject {subj})\\n\"\n",
    "        f\"- Admitted: {adm_row.admittime}    Discharged: {adm_row.dischtime}\\n\"\n",
    "        f\"- Type: {adm_row.admission_type}    ExpireFlag: {adm_row.hospital_expire_flag}\"\n",
    "    )\n",
    "    docs.append(Document(page_content=header, metadata={**base_meta, \"section\":\"header\"}))\n",
    "\n",
    "    # — Diagnoses\n",
    "    if hadm in grouped[\"diagnoses_icd\"].groups:\n",
    "        df_dx = grouped[\"diagnoses_icd\"].get_group(hadm)\n",
    "        lines = [f\"{safe(row.icd_code)}: {safe(row.long_title)}\" for _, row in df_dx.iterrows()]\n",
    "        docs.append(Document(\n",
    "            page_content=\"Diagnoses (ICD):\\n\" + \"\\n\".join(lines),\n",
    "            metadata={**base_meta, \"section\":\"diagnoses\"}\n",
    "        ))\n",
    "\n",
    "    # — Procedures\n",
    "    if hadm in grouped[\"procedures_icd\"].groups:\n",
    "        df_proc = grouped[\"procedures_icd\"].get_group(hadm)\n",
    "        lines = [f\"{safe(row.icd_code)}: {safe(row.long_title)}\" for _, row in df_proc.iterrows()]\n",
    "        docs.append(Document(\n",
    "            page_content=\"Procedures (ICD):\\n\" + \"\\n\".join(lines),\n",
    "            metadata={**base_meta, \"section\":\"procedures\"}\n",
    "        ))\n",
    "    # — Labs\n",
    "    if hadm in grouped[\"labevents\"].groups:\n",
    "        df_labs = grouped[\"labevents\"].get_group(hadm)\n",
    "        lines = []\n",
    "        for _, row in df_labs.iterrows():\n",
    "            chart_time = row.charttime.strftime(\"%Y-%m-%d %H:%M\") if pd.notna(row.charttime) else \"N/A\"\n",
    "            store_time = row.storetime.strftime(\"%Y-%m-%d %H:%M\") if pd.notna(row.storetime) else \"N/A\"\n",
    "            line = f\"{safe(row.itemid)}: {safe(row.label)} - (chart time: {chart_time} ~ store time: {store_time}) {safe(row.value)} {safe(row.valuenum)} | {safe(row.label)} - {safe(row.category)} - {safe(row.fluid)} - {safe(row.priority)} | {safe(row.flag)}\"\n",
    "            lines.append(line)\n",
    "        docs.append(Document(\n",
    "            page_content=\"Labs:\\n\" + \"\\n\".join(lines),\n",
    "            metadata={**base_meta, \"section\":\"labs\"}\n",
    "        ))\n",
    "\n",
    "    # — Microbiology\n",
    "    if hadm in grouped[\"microbiologyevents\"].groups:\n",
    "        df_micro = grouped[\"microbiologyevents\"].get_group(hadm)\n",
    "        lines = []\n",
    "        for _, row in df_micro.iterrows():\n",
    "            chart_time = row.charttime.strftime(\"%Y-%m-%d %H:%M\") if pd.notna(row.charttime) else \"N/A\"\n",
    "            store_time = row.storetime.strftime(\"%Y-%m-%d %H:%M\") if pd.notna(row.storetime) else \"N/A\"\n",
    "            chart_date = row.chartdate.strftime(\"%Y-%m-%d\") if pd.notna(row.chartdate) else \"N/A\"\n",
    "            store_date = row.storedate.strftime(\"%Y-%m-%d\") if pd.notna(row.storedate) else \"N/A\"\n",
    "            line = f\"{safe(row.test_itemid)}: {safe(row.test_name)} - {safe(row.spec_type_desc)} (chart time: {chart_time} ~ store time: {store_time} ~ chart date: {chart_date} ~ store date: {store_date}) | {safe(row.comments)}\"\n",
    "            lines.append(line)\n",
    "        docs.append(Document(\n",
    "            page_content=\"Microbiology:\\n\" + \"\\n\".join(lines),\n",
    "            metadata={**base_meta, \"section\":\"microbiology\"}\n",
    "        ))\n",
    "    # — Prescriptions and EMAR AND POE\n",
    "    if hadm in grouped[\"prescriptions\"].groups:\n",
    "        df_combined = grouped[\"prescriptions\"].get_group(hadm)\n",
    "        lines = []\n",
    "        for _, row in df_combined.iterrows():\n",
    "            order_time = row.ordertime.strftime(\"%Y-%m-%d %H:%M\") if pd.notna(row.ordertime) else \"N/A\"\n",
    "            chart_time = row.charttime.strftime(\"%Y-%m-%d %H:%M\") if pd.notna(row.charttime) else \"N/A\"\n",
    "            line = (\n",
    "                f\"{safe(row.drug_type)} ({safe(row.drug)}) - {safe(row.formulary_drug_cd)} \"\n",
    "                f\"{safe(row.dose_unit_rx)} {safe(row.dose_val_rx)} {safe(row.prod_strength)} | \"\n",
    "                f\"{safe(row.doses_per_24_hrs)} doses/24hrs | Order at {safe(order_time)} ({safe(row.order_type)}, {safe(row.order_status)}) | \"\n",
    "                f\"Administered: {safe(row.medication)} at {safe(chart_time)}\"\n",
    "            )\n",
    "            lines.append(line)\n",
    "        page_content = \"Combined Prescriptions, Orders, and Administration:\\n\" + \"\\n\".join(lines)\n",
    "        docs.append(Document(\n",
    "            page_content=page_content,\n",
    "            metadata={**base_meta, \"section\": \"prescriptions\"}\n",
    "        ))\n",
    "    return docs\n",
    "\n",
    "# build a flat list of section‐level docs\n",
    "section_docs = []\n",
    "for _, adm in admissions_df.iterrows():\n",
    "    section_docs.extend(make_section_docs(adm, grouped))\n",
    "\n",
    "print(f\"Emitted {len(section_docs)} small Documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2826dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 105371 total chunks ready for embedding.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunked_docs = splitter.split_documents(section_docs)\n",
    "print(f\"→ {len(chunked_docs)} total chunks ready for embedding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "037d6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in chunked_docs:\n",
    "    # keep only what you filter on downstream:\n",
    "    md = {\n",
    "      \"hadm_id\": d.metadata[\"hadm_id\"],\n",
    "      \"subject_id\": d.metadata[\"subject_id\"],\n",
    "      \"section\": d.metadata[\"section\"],\n",
    "      \"admittime\": pd.to_datetime(d.metadata[\"admittime\"]),\n",
    "      \"dischtime\": pd.to_datetime(d.metadata[\"dischtime\"]),\n",
    "    }\n",
    "    d.metadata = md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
    "    model_name=\"../models/S-PubMedBert-MS-MARCO\",\n",
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f1847f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[768, 768, 768, 768, 768]\n"
     ]
    }
   ],
   "source": [
    "texts = [doc.page_content for doc in chunked_docs[:5]]\n",
    "vectors = clinical_emb.embed_documents(texts)\n",
    "print([len(v) for v in vectors])  # should each be e.g. 768-dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71927408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the chunked documents to a file\n",
    "with open(\"../mimic_sample_1000/chunked_docs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunked_docs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b55405",
   "metadata": {},
   "source": [
    "Loading different embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fbc43e",
   "metadata": {},
   "source": [
    "Model: all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad6a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "local_model_dir = Path(\"../models/all-MiniLM-L6-v2\")\n",
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# First, download and save the model\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(str(local_model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23eb4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
    "    model_name=\"../models/all-MiniLM-L6-v2\",\n",
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "vectorstore.save_local(\"../vector_stores/faiss_mimic_sample1000_mini-lm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d067ec2",
   "metadata": {},
   "source": [
    "Model: S-PubMedBert-MS-MARCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "local_model_dir = Path(\"../models/S-PubMedBert-MS-MARCO\")\n",
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"pritamdeka/S-PubMedBert-MS-MARCO\"\n",
    "\n",
    "# First, download and save the model\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(str(local_model_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
    "    model_name=\"../models/S-PubMedBert-MS-MARCO\",\n",
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6622cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "vectorstore.save_local(\"../vector_stores/faiss_mimic_sample1000_ms-marco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3cd511",
   "metadata": {},
   "source": [
    "Model: static-retrieval-mrl-en-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6489fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "local_model_dir = Path(\"../models/static-retrieval-mrl-en-v1\")\n",
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"sentence-transformers/static-retrieval-mrl-en-v1\"\n",
    "\n",
    "# First, download and save the model\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(str(local_model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
    "    model_name=\"../models/static-retrieval-mrl-en-v1\",\n",
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15096dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "vectorstore.save_local(\"../vector_stores/faiss_mimic_sample1000_static-retr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2934636e",
   "metadata": {},
   "source": [
    "Model: multi-qa-mpnet-base-cos-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325836c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "local_model_dir = Path(\"../models/multi-qa-mpnet-base-cos-v1\")\n",
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"sentence-transformers/multi-qa-mpnet-base-cos-v1\"\n",
    "\n",
    "# First, download and save the model\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(str(local_model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17aa9faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL 5420\\AppData\\Local\\Temp\\ipykernel_22420\\2591503781.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  clinical_emb = SentenceTransformerEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
    "    model_name=\"./models/multi-qa-mpnet-base-cos-v1\",\n",
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "with open(\"../mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
    "    chunked_docs = pickle.load(f)\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "\n",
    "\n",
    "vectorstore.save_local(\"../vector_stores/faiss_mimic_sample1000_multi-qa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d3e20",
   "metadata": {},
   "source": [
    "Model: BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650d9dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "import pickle\n",
    "with open(\"../mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
    "    chunked_docs = pickle.load(f)\n",
    "\n",
    "# Use HuggingFaceEmbeddings for BiomedBERT\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "clinical_emb = HuggingFaceEmbeddings(\n",
    "    model_name=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
<<<<<<< HEAD
    ")\n"
=======
    " )"
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8edb852",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "vectorstore.save_local(\"vector_stores/faiss_mimic_sample1000_biomedbert\")"
=======
    "vectorstore.save_local(\"../vector_stores/faiss_mimic_sample1000_biomedbert\")"
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76326478",
   "metadata": {},
   "source": [
    "Model: all-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "local_model_dir = Path(\n",
<<<<<<< HEAD
    "    \"./models/all-mpnet-base-v2\")\n",
=======
    "    \"../models/all-mpnet-base-v2\")\n",
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "# First, download and save the model\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(str(local_model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e520d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
<<<<<<< HEAD
    "    model_name=\"./models/all-mpnet-base-v2\",\n",
=======
    "    model_name=\"../models/all-mpnet-base-v2\",\n",
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
<<<<<<< HEAD
    "with open(\"mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
=======
    "with open(\"../mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
    "    chunked_docs = pickle.load(f)\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "vectorstore.save_local(\"vector_stores/faiss_mimic_sample1000_mpnet-v2\")"
=======
    "vectorstore.save_local(\"../vector_stores/faiss_mimic_sample1000_mpnet-v2\")"
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f730c",
   "metadata": {},
   "source": [
    "Model: e5-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "local_model_dir = Path(\n",
<<<<<<< HEAD
    "    \"./models/e5-base-v2\")\n",
=======
    "    \"../models/e5-base-v2\")\n",
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"intfloat/e5-base-v2\"\n",
    "\n",
    "# First, download and save the model\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(str(local_model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e3a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
<<<<<<< HEAD
    "    model_name=\"./models/e5-base-v2\",\n",
=======
    "    model_name=\"../models/e5-base-v2\",\n",
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab31c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
<<<<<<< HEAD
    "with open(\"mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
=======
    "with open(\"../mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
    "    chunked_docs = pickle.load(f)\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "vectorstore.save_local(\"vector_stores/faiss_mimic_sample1000_e5-base\")"
=======
    "vectorstore.save_local(\"../vector_stores/faiss_mimic_sample1000_e5-base\")"
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29e340",
   "metadata": {},
   "source": [
    "TimKond/S-PubMedBert-MedQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f6070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "local_model_dir = Path(\n",
<<<<<<< HEAD
    "    \"./models/e5-base-v2\")\n",
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"intfloat/e5-base-v2\"\n",
=======
    "    \"../models/S-PubMedBert-MedQuAD\")\n",
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"TimKond/S-PubMedBert-MedQuAD\"\n",
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
    "\n",
    "# First, download and save the model\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(str(local_model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabeb2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
<<<<<<< HEAD
    "    model_name=\"./models/e5-base-v2\",\n",
=======
    "    model_name=\"../models/S-PubMedBert-MedQuAD\",\n",
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
<<<<<<< HEAD
    "with open(\"mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
=======
    "with open(\"../mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
    "    chunked_docs = pickle.load(f)\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "vectorstore.save_local(\"vector_stores/faiss_mimic_sample1000_e5-base\")"
=======
    "vectorstore.save_local(\n",
    "    \"../vector_stores/faiss_mimic_sample1000_MedQuAD\")"
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66939e",
   "metadata": {},
   "source": [
    "pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31607537",
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "local_model_dir = Path(\n",
    "    \"./models/e5-base-v2\")\n",
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"intfloat/e5-base-v2\"\n",
    "\n",
    "# First, download and save the model\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(str(local_model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756be25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
    "    model_name=\"./models/e5-base-v2\",\n",
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd52be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "with open(\"mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
    "    chunked_docs = pickle.load(f)\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "\n",
    "\n",
    "vectorstore.save_local(\"vector_stores/faiss_mimic_sample1000_e5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf2c87",
   "metadata": {},
=======
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "local_model_dir = Path(\n",
    "    \"../models/BioBERT-mnli-snli-scinli-scitail-mednli-stsb\")\n",
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb\"\n",
    "\n",
    "# First, download and save the model\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(str(local_model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756be25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
    "    model_name=\"../models/BioBERT-mnli-snli-scinli-scitail-mednli-stsb\",\n",
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd52be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "with open(\"../mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
    "    chunked_docs = pickle.load(f)\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "\n",
    "\n",
    "vectorstore.save_local(\"../vector_stores/faiss_mimic_sample1000_BioBERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf2c87",
   "metadata": {},
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
   "source": [
    "FremyCompany/BioLORD-2023-C"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "42556170",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 23,
   "id": "42556170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name FremyCompany/BioLORD-2023-C. Creating a new one with mean pooling.\n"
     ]
    }
   ],
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "local_model_dir = Path(\n",
<<<<<<< HEAD
    "    \"./models/e5-base-v2\")\n",
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"intfloat/e5-base-v2\"\n",
=======
    "    \"../models/BioLORD-2023-C\")\n",
    "local_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"FremyCompany/BioLORD-2023-C\"\n",
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
    "\n",
    "# First, download and save the model\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(str(local_model_dir))"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
    "    model_name=\"./models/e5-base-v2\",\n",
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252cf666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "with open(\"mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
    "    chunked_docs = pickle.load(f)\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "\n",
    "\n",
    "vectorstore.save_local(\"vector_stores/faiss_mimic_sample1000_e5-base\")"
   ]
=======
>>>>>>> 7c90853c1390cb163736bc666c7e2b148c1988b4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "clinical_emb = SentenceTransformerEmbeddings(\n",
    "    model_name=\"../models/BioLORD-2023-C\",\n",
    "    encode_kwargs={\"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252cf666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "with open(\"../mimic_sample_1000/chunked_docs.pkl\", \"rb\") as f:\n",
    "    chunked_docs = pickle.load(f)\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunked_docs, clinical_emb)\n",
    "\n",
    "\n",
    "vectorstore.save_local(\"../vector_stores/faiss_mimic_sample1000_BioLORD\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
